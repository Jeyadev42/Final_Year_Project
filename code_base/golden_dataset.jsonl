{"id": "q1", "query": "What is a classifier model in machine learning?", "gold_answer": "A classifier model is a supervised learning method that assigns inputs to predefined categories using patterns learned from labeled data. Examples include logistic regression, SVMs, decision trees, and neural network classifiers.", "notes": "ML basics"}
{"id": "q2", "query": "Explain overfitting.", "gold_answer": "Overfitting occurs when a model memorizes training data, including noise, resulting in poor generalization to new data. It can be reduced using regularization, early stopping, dropout, and more training data.", "notes": "ML generalization"}
{"id": "q3", "query": "What is a confusion matrix?", "gold_answer": "A confusion matrix is a table summarizing classification results using true positives, true negatives, false positives, and false negatives. It is used to compute metrics like precision, recall, and accuracy.", "notes": "Evaluation metrics"}
{"id": "q4", "query": "What is supervised learning?", "gold_answer": "Supervised learning trains models on labeled data to perform tasks like classification and regression. The objective is to map inputs to outputs using examples with known labels.", "notes": "ML taxonomy"}
{"id": "q5", "query": "What is unsupervised learning?", "gold_answer": "Unsupervised learning discovers patterns in unlabeled data, such as clusters or latent structure. Common techniques include clustering and dimensionality reduction.", "notes": "ML taxonomy"}
{"id": "q6", "query": "What is a neural network?", "gold_answer": "A neural network is a computational model composed of interconnected neurons organized in layers that learn representations of data through forward propagation and backpropagation.", "notes": "Deep learning basics"}
{"id": "q7", "query": "What is PCA?", "gold_answer": "PCA is a dimensionality reduction method that transforms correlated variables into orthogonal components ordered by variance. It captures key structure while reducing noise.", "notes": "Math + ML"}
{"id": "q8", "query": "What is a feature in machine learning?", "gold_answer": "A feature is a measurable attribute or input variable used by machine learning models to make predictions.", "notes": "ML terminology"}
{"id": "q9", "query": "What is cloud computing?", "gold_answer": "Cloud computing is the delivery of computing, storage, and networking over the internet with elastic, on-demand provisioning. Models include IaaS, PaaS, and SaaS.", "notes": "Cloud fundamentals"}
{"id": "q10", "query": "What is Big O notation?", "gold_answer": "Big O notation describes how an algorithm's time or space usage scales with input size, identifying growth rates such as O(n), O(log n), and O(n^2).", "notes": "CS fundamentals"}
{"id": "q11", "query": "What is an API?", "gold_answer": "An API is an interface that allows software components to communicate using predefined rules, enabling modularity and integration.", "notes": "Software basics"}
{"id": "q12", "query": "What is SQL used for?", "gold_answer": "SQL is used to manage and query relational databases through commands like SELECT, INSERT, UPDATE, and DELETE.", "notes": "Database basics"}
{"id": "q13", "query": "What is normalization in databases?", "gold_answer": "Normalization organizes relational tables to reduce redundancy and preserve data integrity using normal forms like 1NF, 2NF, and 3NF.", "notes": "Database integrity"}
{"id": "q14", "query": "What is the purpose of an index in databases?", "gold_answer": "An index improves query performance by enabling fast lookup of rows based on key columns, similar to a bookâ€™s index.", "notes": "Database performance"}
{"id": "q15", "query": "Explain the difference between RAM and storage.", "gold_answer": "RAM is volatile memory used for active processes, while storage (SSD/HDD) holds persistent data. RAM is faster but temporary.", "notes": "CS hardware basics"}
{"id": "q16", "query": "Explain the bias-variance tradeoff.", "gold_answer": "The bias-variance tradeoff balances model simplicity and complexity. High bias causes underfitting, high variance causes overfitting. Optimal models minimize total error from both sources.", "notes": "ML theory"}
{"id": "q17", "query": "Explain gradient descent.", "gold_answer": "Gradient descent optimizes model parameters by iteratively moving them in the negative gradient direction of the loss function to reach a minimum.", "notes": "Optimization"}
{"id": "q18", "query": "What is logistic regression?", "gold_answer": "Logistic regression is a classification algorithm that models probability using the logistic function and makes predictions based on a threshold.", "notes": "ML models"}
{"id": "q19", "query": "What are word embeddings?", "gold_answer": "Word embeddings map words to dense vector spaces where semantic similarity corresponds to geometric proximity. Examples include Word2Vec and GloVe.", "notes": "NLP representation"}
{"id": "q20", "query": "Explain TF-IDF.", "gold_answer": "TF-IDF weighs words by combining term frequency with inverse document frequency, giving higher scores to informative words and lower scores to ubiquitous ones.", "notes": "NLP features"}
{"id": "q21", "query": "Explain convolution in CNNs.", "gold_answer": "Convolution applies a kernel across an input to extract spatial features. It reduces parameters while preserving local patterns.", "notes": "Deep learning"}
{"id": "q22", "query": "What is dropout in neural networks?", "gold_answer": "Dropout randomly disables neurons during training to prevent overfitting and encourage robustness.", "notes": "DL regularization"}
{"id": "q23", "query": "Explain the difference between RNNs and LSTMs.", "gold_answer": "RNNs suffer from vanishing gradients and short memory. LSTMs mitigate this by adding gates that control information flow and preserve long-term context.", "notes": "DL sequence models"}
{"id": "q24", "query": "What is a decision tree?", "gold_answer": "A decision tree splits data based on feature conditions to produce a tree-like structure for classification or regression tasks.", "notes": "ML models"}
{"id": "q25", "query": "Explain K-means clustering.", "gold_answer": "K-means partitions data into K clusters by iteratively assigning points to nearest centroids and updating centroids until convergence.", "notes": "Unsupervised learning"}
{"id": "q26", "query": "What is a data pipeline?", "gold_answer": "A data pipeline automates data collection, processing, transformation, and storage steps for reliable and repeatable data flow.", "notes": "DE fundamentals"}
{"id": "q27", "query": "What is a microservice architecture?", "gold_answer": "Microservices split applications into small, independently deployable services that communicate via APIs, improving scalability and maintainability.", "notes": "Software architecture"}
{"id": "q28", "query": "Explain CAP theorem.", "gold_answer": "CAP theorem states that distributed systems can guarantee only two of consistency, availability, and partition tolerance. Partition tolerance is unavoidable.", "notes": "Distributed systems"}
{"id": "q29", "query": "What is vectorization in ML?", "gold_answer": "Vectorization converts raw inputs into numerical features for models, enabling linear algebra-based learning and fast computations.", "notes": "ML preprocessing"}
{"id": "q30", "query": "Explain cross-validation.", "gold_answer": "Cross-validation splits data into folds and trains models over different subsets to estimate generalization performance.", "notes": "Evaluation"}
{"id": "q31", "query": "What is containerization and why is Docker used?", "gold_answer": "Containerization packages apps with dependencies into isolated environments. Docker provides reproducibility and portability using images and layered filesystems.", "notes": "DevOps"}
{"id": "q32", "query": "What is an ETL process?", "gold_answer": "ETL extracts data from sources, transforms it into usable formats, and loads it into target systems such as data warehouses.", "notes": "Data engineering"}
{"id": "q33", "query": "What is vector search and how does it work?", "gold_answer": "Vector search retrieves items based on vector similarity using embeddings and distance metrics like cosine similarity or Euclidean distance.", "notes": "AI search"}
{"id": "q34", "query": "Explain supervised vs reinforcement learning.", "gold_answer": "Supervised learning trains on labeled inputs, whereas reinforcement learning trains an agent to maximize cumulative rewards through trial and error.", "notes": "AI paradigms"}
{"id": "q35", "query": "What is a transformer model?", "gold_answer": "Transformers process sequences using self-attention instead of recurrence, enabling parallelism and capturing long-range dependencies.", "notes": "NLP advanced"}
{"id": "q36", "query": "Explain the vanishing gradient problem and solutions.", "gold_answer": "Vanishing gradients occur when gradients shrink exponentially during backpropagation, slowing learning in deep networks. Solutions include ReLU activations, residual connections, layer normalization, and better weight initialization techniques such as Xavier or He initialization.", "notes": "DL optimization"}
{"id": "q37", "query": "What is a probabilistic graphical model?", "gold_answer": "A probabilistic graphical model represents conditional dependencies among variables using graphs such as Bayesian networks or Markov random fields, enabling structured probabilistic reasoning.", "notes": "ML advanced"}
{"id": "q38", "query": "Explain Q-learning.", "gold_answer": "Q-learning is a reinforcement learning algorithm that learns an action-value function estimating expected return for state-action pairs. It updates Q-values using reward and discounted future values.", "notes": "RL advanced"}
{"id": "q39", "query": "What is attention in neural networks?", "gold_answer": "Attention mechanisms compute weighted combinations of input features, allowing models to focus on relevant information dynamically. In transformers, self-attention captures relationships across tokens.", "notes": "DL attention"}
{"id": "q40", "query": "Explain the difference between batch, mini-batch, and stochastic gradient descent.", "gold_answer": "Batch GD uses the full dataset per update, SGD uses one sample per update, and mini-batch GD uses small batches. Mini-batch is widely used due to stability and efficiency.", "notes": "Optimization advanced"}
{"id": "q41", "query": "What is approximate nearest neighbor search?", "gold_answer": "ANN search retrieves vectors similar to a query vector efficiently using algorithms like HNSW, IVF, or LSH, trading exactness for speed and scalability.", "notes": "Vector search"}
{"id": "q42", "query": "Explain distributed training in deep learning.", "gold_answer": "Distributed training splits computations across multiple GPUs or machines using data parallelism or model parallelism, synchronized by communication protocols like NCCL or Horovod.", "notes": "DL systems"}
{"id": "q43", "query": "What is a data lakehouse?", "gold_answer": "A lakehouse unifies data warehouses and data lakes by providing ACID transactions, schema enforcement, and performance optimizations on top of object storage.", "notes": "DE advanced"}
{"id": "q44", "query": "Explain how indexing works in search engines.", "gold_answer": "Search engines tokenize content, generate inverted indexes mapping terms to documents, compute ranking features, and enable fast retrieval via index lookup structures.", "notes": "IR systems"}
{"id": "q45", "query": "What is differential privacy?", "gold_answer": "Differential privacy adds controlled noise to queries or models to protect individual records while preserving overall data utility. It ensures that outputs change minimally when a single record is modified.", "notes": "AI ethics / privacy"}
{"id": "q46", "query": "Explain zero-shot learning.", "gold_answer": "Zero-shot learning enables models to make predictions on classes not seen during training using external semantic representations such as embeddings or textual descriptions.", "notes": "ML generalization"}
{"id": "q47", "query": "What causes model collapse in LLMs?", "gold_answer": "Model collapse occurs when training on synthetic data causes drift toward degenerate distributions, reducing diversity and factual accuracy. It can be prevented with data curation and human-grounded datasets.", "notes": "LLM risks"}
{"id": "q48", "query": "Explain vector quantization in generative models.", "gold_answer": "Vector quantization maps continuous encodings to discrete tokens using a learned codebook, enabling models like VQ-VAE to operate in latent discrete spaces for stable generative training.", "notes": "Generative models"}
{"id": "q49", "query": "What is a retryable vs non-retryable error in distributed systems?", "gold_answer": "Retryable errors result from transient issues like timeouts or temporary network failures, while non-retryable errors stem from invalid requests or logic issues that cannot be resolved by retrying.", "notes": "Distributed systems"}
{"id": "q50", "query": "Explain consistency models in distributed databases.", "gold_answer": "Consistency models describe how reads reflect writes in distributed systems. Examples include strong consistency, eventual consistency, causal consistency, and read-after-write consistency.", "notes": "Distributed computing"}
